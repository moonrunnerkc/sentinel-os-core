llm:
  backend: llama-cpp
  model_path: data/models/llama-2-7b.Q4_K_M.gguf
  temperature: 0.0
  seed: 42
  gpu_layers: 0
  min_vram_gb: 4.0

performance:
  max_beliefs: 10000
  max_episodes: 10000
  cache_size: 1000

features:
  # neuromorphic mode requires brian2 - will fail if unavailable
  neuromorphic_mode: false

# verification settings
verification:
  enabled: true
  check_invariants_on_transition: true
  property_test_iterations: 50

# privacy settings
privacy:
  total_epsilon: 1.0
  total_delta: 1.0e-5
  composition_mode: basic

# isolation settings
isolation:
  level: python
  timeout_seconds: 30
  use_firejail: false
  timeout_seconds: 30
  network_enabled: false
